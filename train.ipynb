{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465149cd-f249-4d74-8006-c9c1aea35e8e",
   "metadata": {},
   "source": [
    "### this notebook is for training our Agent in the lux environment and see how well we do :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fef873-ccc1-4ce2-bb74-d5a74cee1479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from luxai_s3.wrappers import LuxAIS3GymEnv\n",
    "from agent import Agent\n",
    "from network import AgentNetwork, compute_network_difference, has_converged\n",
    "from rewards import calculate_rewards\n",
    "from ac2methods import compute_advantages, compute_weight_loss, compute_action_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929f67f5-870e-4fa9-a0e1-47086019e6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-01-25 18:53:14,325:jax._src.xla_bridge:987: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "# reset our gym environment\n",
    "env = LuxAIS3GymEnv(numpy_output=True)\n",
    "obs, info = env.reset()\n",
    "\n",
    "env_cfg = info[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c346dbe-184e-44ea-86c9-36f360152951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set torch device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98cf25d8-8d9e-462e-bacc-8bf36350b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set players\n",
    "players = {\n",
    "    \"player_0\": Agent(\"player_0\", env_cfg, AgentNetwork((env_cfg[\"map_width\"], env_cfg[\"map_height\"]), env_cfg[\"max_units\"], 6).to(device), device),\n",
    "    \"player_1\": Agent(\"player_1\", env_cfg, AgentNetwork((env_cfg[\"map_width\"], env_cfg[\"map_height\"]), env_cfg[\"max_units\"], 6).to(device), device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ecc61c-0b05-4fdc-9ba7-895cc461d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer for network\n",
    "optimizer = torch.optim.Adam(players[\"player_0\"].net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "906c9da1-b84f-4932-b22c-20124a7ca50e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode num: 0\n",
      "Step 0 of episode 0 completed. Loss: 1359669.0000\n",
      "Step 1 of episode 0 completed. Loss: 1343467.2500\n",
      "Step 2 of episode 0 completed. Loss: 1321682.6250\n",
      "Step 3 of episode 0 completed. Loss: 1311262.8750\n",
      "Step 4 of episode 0 completed. Loss: 1312832.2500\n",
      "Step 5 of episode 0 completed. Loss: 1326217.2500\n",
      "Step 6 of episode 0 completed. Loss: 1331478.5000\n",
      "Step 7 of episode 0 completed. Loss: 1349459.7500\n",
      "Step 8 of episode 0 completed. Loss: 1356977.5000\n",
      "Step 9 of episode 0 completed. Loss: 1362125.0000\n",
      "Step 10 of episode 0 completed. Loss: 1355238.2500\n",
      "Step 11 of episode 0 completed. Loss: 1326988.7500\n",
      "Step 12 of episode 0 completed. Loss: 1259802.0000\n",
      "Step 13 of episode 0 completed. Loss: 1203491.1250\n",
      "Step 14 of episode 0 completed. Loss: 1191683.7500\n",
      "Step 15 of episode 0 completed. Loss: 1116679.0000\n",
      "Step 16 of episode 0 completed. Loss: 1040877.7500\n",
      "Step 17 of episode 0 completed. Loss: 988613.8750\n",
      "Step 18 of episode 0 completed. Loss: 930557.7500\n",
      "Step 19 of episode 0 completed. Loss: 890089.7500\n",
      "Step 20 of episode 0 completed. Loss: 842427.2500\n",
      "Step 21 of episode 0 completed. Loss: 819632.6250\n",
      "Step 22 of episode 0 completed. Loss: 797979.0625\n",
      "Step 23 of episode 0 completed. Loss: 752037.6250\n",
      "Step 24 of episode 0 completed. Loss: 714348.1250\n",
      "Step 25 of episode 0 completed. Loss: 703289.0000\n",
      "Step 26 of episode 0 completed. Loss: 678843.0000\n",
      "Step 27 of episode 0 completed. Loss: 646230.7500\n",
      "Step 28 of episode 0 completed. Loss: 612217.6250\n",
      "Step 29 of episode 0 completed. Loss: 574667.8125\n",
      "Step 30 of episode 0 completed. Loss: 536989.7500\n",
      "Step 31 of episode 0 completed. Loss: 486717.3125\n",
      "Step 32 of episode 0 completed. Loss: 457238.3125\n",
      "Step 33 of episode 0 completed. Loss: 425299.8750\n",
      "Step 34 of episode 0 completed. Loss: 398624.8750\n",
      "Step 35 of episode 0 completed. Loss: 347576.0000\n",
      "Step 36 of episode 0 completed. Loss: 287096.9375\n",
      "Step 37 of episode 0 completed. Loss: 232097.6406\n",
      "Step 38 of episode 0 completed. Loss: 183158.2812\n",
      "Step 39 of episode 0 completed. Loss: 145199.4375\n",
      "Step 40 of episode 0 completed. Loss: 122369.5078\n",
      "Step 41 of episode 0 completed. Loss: 104209.1719\n",
      "Step 42 of episode 0 completed. Loss: 87677.1094\n",
      "Step 43 of episode 0 completed. Loss: 79072.7812\n",
      "Step 44 of episode 0 completed. Loss: 67113.4375\n",
      "Step 45 of episode 0 completed. Loss: 56580.9609\n",
      "Step 46 of episode 0 completed. Loss: 49153.1328\n",
      "Step 47 of episode 0 completed. Loss: 43085.3086\n",
      "Step 48 of episode 0 completed. Loss: 36752.0000\n",
      "Step 49 of episode 0 completed. Loss: 32645.7422\n",
      "Step 50 of episode 0 completed. Loss: 29522.7305\n",
      "Step 51 of episode 0 completed. Loss: 27248.3633\n",
      "Step 52 of episode 0 completed. Loss: 25645.3145\n",
      "Step 53 of episode 0 completed. Loss: 22405.0703\n",
      "Step 54 of episode 0 completed. Loss: 20882.5156\n",
      "Step 55 of episode 0 completed. Loss: 19853.7617\n",
      "Step 56 of episode 0 completed. Loss: 20301.0781\n",
      "Step 57 of episode 0 completed. Loss: 18336.9453\n",
      "Step 58 of episode 0 completed. Loss: 15567.9268\n",
      "Step 59 of episode 0 completed. Loss: 15374.5195\n",
      "Step 60 of episode 0 completed. Loss: 13093.7656\n",
      "Step 61 of episode 0 completed. Loss: 10145.7080\n",
      "Step 62 of episode 0 completed. Loss: 8663.3701\n",
      "Step 63 of episode 0 completed. Loss: 5141.5088\n",
      "Step 64 of episode 0 completed. Loss: 3082.0566\n",
      "Step 65 of episode 0 completed. Loss: 2105.2646\n",
      "Step 66 of episode 0 completed. Loss: 531.3947\n",
      "Step 67 of episode 0 completed. Loss: -554.9509\n",
      "Step 68 of episode 0 completed. Loss: -1198.8091\n",
      "Step 69 of episode 0 completed. Loss: -1150.5959\n",
      "Step 70 of episode 0 completed. Loss: -1320.5133\n",
      "Step 71 of episode 0 completed. Loss: -1264.1792\n",
      "Step 72 of episode 0 completed. Loss: -1404.1572\n",
      "Step 73 of episode 0 completed. Loss: -1507.4259\n",
      "Step 74 of episode 0 completed. Loss: -1589.7024\n",
      "Step 75 of episode 0 completed. Loss: -1658.8716\n",
      "Step 76 of episode 0 completed. Loss: -1717.3964\n",
      "Step 77 of episode 0 completed. Loss: -1766.6620\n",
      "Step 78 of episode 0 completed. Loss: -1808.0364\n",
      "Step 79 of episode 0 completed. Loss: -1842.9675\n",
      "Step 80 of episode 0 completed. Loss: -1872.8757\n",
      "Step 81 of episode 0 completed. Loss: -1747.8701\n",
      "Step 82 of episode 0 completed. Loss: -1564.2595\n",
      "Step 83 of episode 0 completed. Loss: -1323.6282\n",
      "Step 84 of episode 0 completed. Loss: -1023.2659\n",
      "Step 85 of episode 0 completed. Loss: -659.9459\n",
      "Step 86 of episode 0 completed. Loss: -236.2125\n",
      "Step 87 of episode 0 completed. Loss: 243.1145\n",
      "Step 88 of episode 0 completed. Loss: 777.8596\n",
      "Step 89 of episode 0 completed. Loss: 1382.1892\n",
      "Step 90 of episode 0 completed. Loss: 1079.3649\n",
      "Step 91 of episode 0 completed. Loss: 791.9518\n",
      "Step 92 of episode 0 completed. Loss: 518.3624\n",
      "Step 93 of episode 0 completed. Loss: 253.4184\n",
      "Step 94 of episode 0 completed. Loss: -7.0323\n",
      "Step 95 of episode 0 completed. Loss: -261.6534\n",
      "Step 96 of episode 0 completed. Loss: -507.8234\n",
      "Step 97 of episode 0 completed. Loss: -741.6121\n",
      "Step 98 of episode 0 completed. Loss: -964.6566\n",
      "Step 99 of episode 0 completed. Loss: -1177.3005\n",
      "Step 100 of episode 0 completed. Loss: 932.6453\n",
      "Step 101 of episode 0 completed. Loss: 1397.7499\n",
      "Step 102 of episode 0 completed. Loss: 162.5328\n",
      "Step 103 of episode 0 completed. Loss: -823.9409\n",
      "Step 104 of episode 0 completed. Loss: 16357.1025\n",
      "Step 105 of episode 0 completed. Loss: 10945.4492\n",
      "Step 106 of episode 0 completed. Loss: 6526.1040\n",
      "Step 107 of episode 0 completed. Loss: 29267.4648\n",
      "Step 108 of episode 0 completed. Loss: 18841.8086\n",
      "Step 109 of episode 0 completed. Loss: 10392.4355\n",
      "Step 110 of episode 0 completed. Loss: 31635.9102\n",
      "Step 111 of episode 0 completed. Loss: 18703.3945\n",
      "Step 112 of episode 0 completed. Loss: 9934.2539\n",
      "Step 113 of episode 0 completed. Loss: 29650.1699\n",
      "Step 114 of episode 0 completed. Loss: 16679.7539\n",
      "Step 115 of episode 0 completed. Loss: 8364.8604\n",
      "Step 116 of episode 0 completed. Loss: 27163.7910\n",
      "Step 117 of episode 0 completed. Loss: 14714.6621\n",
      "Step 118 of episode 0 completed. Loss: 6244.1367\n",
      "Step 119 of episode 0 completed. Loss: 22490.5625\n",
      "Step 120 of episode 0 completed. Loss: 8991.8672\n",
      "Step 121 of episode 0 completed. Loss: 1592.8953\n",
      "Step 122 of episode 0 completed. Loss: 8212.3818\n",
      "Step 123 of episode 0 completed. Loss: 195.5456\n",
      "Step 124 of episode 0 completed. Loss: -1032.4016\n",
      "Step 125 of episode 0 completed. Loss: 1840.8638\n",
      "Step 126 of episode 0 completed. Loss: -1418.0933\n",
      "Step 127 of episode 0 completed. Loss: -1775.3376\n",
      "Step 128 of episode 0 completed. Loss: 1373.1211\n",
      "Step 129 of episode 0 completed. Loss: -1535.1143\n",
      "Step 130 of episode 0 completed. Loss: -1771.4518\n",
      "Step 131 of episode 0 completed. Loss: 1825.4135\n",
      "Step 132 of episode 0 completed. Loss: -1156.2715\n",
      "Step 133 of episode 0 completed. Loss: -1946.4413\n",
      "Step 134 of episode 0 completed. Loss: 1721.3464\n",
      "Step 135 of episode 0 completed. Loss: 24451.9922\n",
      "Step 136 of episode 0 completed. Loss: 32248.3457\n",
      "Step 137 of episode 0 completed. Loss: 90932.8906\n",
      "Step 138 of episode 0 completed. Loss: 101554.3281\n",
      "Step 139 of episode 0 completed. Loss: 110438.9844\n",
      "Step 140 of episode 0 completed. Loss: 191065.7031\n",
      "Step 141 of episode 0 completed. Loss: 244959.7500\n",
      "Step 142 of episode 0 completed. Loss: 286967.0625\n",
      "Step 143 of episode 0 completed. Loss: 462963.0312\n",
      "Step 144 of episode 0 completed. Loss: 531826.0625\n",
      "Step 145 of episode 0 completed. Loss: 530599.7500\n",
      "Step 146 of episode 0 completed. Loss: 617187.2500\n",
      "Step 147 of episode 0 completed. Loss: 529022.8750\n",
      "Step 148 of episode 0 completed. Loss: 250876.8125\n",
      "Step 149 of episode 0 completed. Loss: 102331.6875\n",
      "Step 150 of episode 0 completed. Loss: 5917.2524\n",
      "Step 151 of episode 0 completed. Loss: 14577.8555\n",
      "Step 152 of episode 0 completed. Loss: 22856.1680\n",
      "Step 153 of episode 0 completed. Loss: 14638.3037\n",
      "Step 154 of episode 0 completed. Loss: 13686.1016\n",
      "Step 155 of episode 0 completed. Loss: 10175.9512\n",
      "Step 156 of episode 0 completed. Loss: 8019.3955\n",
      "Step 157 of episode 0 completed. Loss: 6412.5127\n",
      "Step 158 of episode 0 completed. Loss: 4045.3423\n",
      "Step 159 of episode 0 completed. Loss: 2529.8511\n",
      "Step 160 of episode 0 completed. Loss: 785.1935\n",
      "Step 161 of episode 0 completed. Loss: 785.4954\n",
      "Step 162 of episode 0 completed. Loss: 1066.7318\n",
      "Step 163 of episode 0 completed. Loss: 1366.5002\n",
      "Step 164 of episode 0 completed. Loss: 634.7247\n",
      "Step 165 of episode 0 completed. Loss: 510.6145\n",
      "Step 166 of episode 0 completed. Loss: 1940.0305\n",
      "Step 167 of episode 0 completed. Loss: 1990.4896\n",
      "Step 168 of episode 0 completed. Loss: 4274.9443\n",
      "Step 169 of episode 0 completed. Loss: 6270.5977\n",
      "Step 170 of episode 0 completed. Loss: 8676.3740\n",
      "Step 171 of episode 0 completed. Loss: 12592.4219\n",
      "Step 172 of episode 0 completed. Loss: 18140.3750\n",
      "Step 173 of episode 0 completed. Loss: 24367.9219\n",
      "Step 174 of episode 0 completed. Loss: 33170.9219\n",
      "Step 175 of episode 0 completed. Loss: 39760.7578\n",
      "Step 176 of episode 0 completed. Loss: 30347.7969\n",
      "Step 177 of episode 0 completed. Loss: 17291.3789\n",
      "Step 178 of episode 0 completed. Loss: 17366.5586\n",
      "Step 179 of episode 0 completed. Loss: 18738.8145\n",
      "Step 180 of episode 0 completed. Loss: 20413.6211\n",
      "Step 181 of episode 0 completed. Loss: 27689.3809\n",
      "Step 182 of episode 0 completed. Loss: 35967.2695\n",
      "Step 183 of episode 0 completed. Loss: 41022.1797\n",
      "Step 184 of episode 0 completed. Loss: 45159.0859\n",
      "Step 185 of episode 0 completed. Loss: 50635.0625\n",
      "Step 186 of episode 0 completed. Loss: 58085.2812\n",
      "Step 187 of episode 0 completed. Loss: 60709.2344\n",
      "Step 188 of episode 0 completed. Loss: 59700.3750\n",
      "Step 189 of episode 0 completed. Loss: 59188.7969\n",
      "Step 190 of episode 0 completed. Loss: 62019.3828\n",
      "Step 191 of episode 0 completed. Loss: 58666.1797\n",
      "Step 192 of episode 0 completed. Loss: 56665.4375\n",
      "Step 193 of episode 0 completed. Loss: 50252.0195\n",
      "Step 194 of episode 0 completed. Loss: 47091.7461\n",
      "Step 195 of episode 0 completed. Loss: 46398.8047\n",
      "Step 196 of episode 0 completed. Loss: 43758.4922\n",
      "Step 197 of episode 0 completed. Loss: 39820.2266\n",
      "Step 198 of episode 0 completed. Loss: 33908.1484\n",
      "Step 199 of episode 0 completed. Loss: 27593.1289\n",
      "Step 200 of episode 0 completed. Loss: 24873.4707\n",
      "Step 201 of episode 0 completed. Loss: 35564.7734\n",
      "Step 202 of episode 0 completed. Loss: 357.9536\n",
      "Step 203 of episode 0 completed. Loss: -473.6185\n",
      "Step 204 of episode 0 completed. Loss: -889.1680\n",
      "Step 205 of episode 0 completed. Loss: 6479.4639\n",
      "Step 206 of episode 0 completed. Loss: 6989.5010\n",
      "Step 207 of episode 0 completed. Loss: 7128.3159\n",
      "Step 208 of episode 0 completed. Loss: 30939.6016\n",
      "Step 209 of episode 0 completed. Loss: 28141.5586\n",
      "Step 210 of episode 0 completed. Loss: 24865.0078\n",
      "Step 211 of episode 0 completed. Loss: 56424.8672\n",
      "Step 212 of episode 0 completed. Loss: 47212.4961\n",
      "Step 213 of episode 0 completed. Loss: 35044.1016\n",
      "Step 214 of episode 0 completed. Loss: 65528.7891\n",
      "Step 215 of episode 0 completed. Loss: 52002.8672\n",
      "Step 216 of episode 0 completed. Loss: 39494.3984\n",
      "Step 217 of episode 0 completed. Loss: 60959.0391\n",
      "Step 218 of episode 0 completed. Loss: 38619.7500\n",
      "Step 219 of episode 0 completed. Loss: 15771.7832\n",
      "Step 220 of episode 0 completed. Loss: 26188.9512\n",
      "Step 221 of episode 0 completed. Loss: 8761.4150\n",
      "Step 222 of episode 0 completed. Loss: 494.8297\n",
      "Step 223 of episode 0 completed. Loss: 2293.9048\n",
      "Step 224 of episode 0 completed. Loss: -793.9327\n",
      "Step 225 of episode 0 completed. Loss: 1099.0792\n",
      "Step 226 of episode 0 completed. Loss: -810.2567\n",
      "Step 227 of episode 0 completed. Loss: 339.5899\n",
      "Step 228 of episode 0 completed. Loss: 3546.5798\n",
      "Step 229 of episode 0 completed. Loss: 884.8531\n",
      "Step 230 of episode 0 completed. Loss: 4895.4580\n",
      "Step 231 of episode 0 completed. Loss: 9309.1572\n",
      "Step 232 of episode 0 completed. Loss: 986.4172\n",
      "Step 233 of episode 0 completed. Loss: 4228.1152\n",
      "Step 234 of episode 0 completed. Loss: 8014.0156\n",
      "Step 235 of episode 0 completed. Loss: 4595.1475\n",
      "Step 236 of episode 0 completed. Loss: 8346.4375\n",
      "Step 237 of episode 0 completed. Loss: 12829.6270\n",
      "Step 238 of episode 0 completed. Loss: 47512.5391\n",
      "Step 239 of episode 0 completed. Loss: 58276.8398\n",
      "Step 240 of episode 0 completed. Loss: 66845.1562\n",
      "Step 241 of episode 0 completed. Loss: 29054.2227\n",
      "Step 242 of episode 0 completed. Loss: 32507.0391\n",
      "Step 243 of episode 0 completed. Loss: 33310.1016\n",
      "Step 244 of episode 0 completed. Loss: 65467.4609\n",
      "Step 245 of episode 0 completed. Loss: 63875.8516\n",
      "Step 246 of episode 0 completed. Loss: 58908.8984\n",
      "Step 247 of episode 0 completed. Loss: 94274.0938\n",
      "Step 248 of episode 0 completed. Loss: 85030.6250\n",
      "Step 249 of episode 0 completed. Loss: 80590.3281\n",
      "Step 250 of episode 0 completed. Loss: 59141.0781\n",
      "Step 251 of episode 0 completed. Loss: 43106.0547\n",
      "Step 252 of episode 0 completed. Loss: 24771.5000\n",
      "Step 253 of episode 0 completed. Loss: 11111.6895\n",
      "Step 254 of episode 0 completed. Loss: 2910.6184\n",
      "Step 255 of episode 0 completed. Loss: 94.0099\n",
      "Step 256 of episode 0 completed. Loss: 304.5138\n",
      "Step 257 of episode 0 completed. Loss: 705.1239\n",
      "Step 258 of episode 0 completed. Loss: 115.8873\n",
      "Step 259 of episode 0 completed. Loss: 401.2767\n",
      "Step 260 of episode 0 completed. Loss: -31.1030\n",
      "Step 261 of episode 0 completed. Loss: -371.2324\n",
      "Step 262 of episode 0 completed. Loss: 656.3298\n",
      "Step 263 of episode 0 completed. Loss: 1350.6240\n",
      "Step 264 of episode 0 completed. Loss: 1174.6481\n",
      "Step 265 of episode 0 completed. Loss: 1417.9320\n",
      "Step 266 of episode 0 completed. Loss: 2125.8518\n",
      "Step 267 of episode 0 completed. Loss: 2536.3882\n",
      "Step 268 of episode 0 completed. Loss: 3549.7979\n",
      "Step 269 of episode 0 completed. Loss: 6379.0737\n",
      "Step 270 of episode 0 completed. Loss: 9613.9688\n",
      "Step 271 of episode 0 completed. Loss: 11424.1270\n",
      "Step 272 of episode 0 completed. Loss: 12702.5791\n",
      "Step 273 of episode 0 completed. Loss: 12990.0254\n",
      "Step 274 of episode 0 completed. Loss: 12283.6016\n",
      "Step 275 of episode 0 completed. Loss: 10023.3330\n",
      "Step 276 of episode 0 completed. Loss: 12780.9561\n",
      "Step 277 of episode 0 completed. Loss: 11090.4082\n",
      "Step 278 of episode 0 completed. Loss: 13820.8379\n",
      "Step 279 of episode 0 completed. Loss: 14704.6543\n",
      "Step 280 of episode 0 completed. Loss: 14790.4004\n",
      "Step 281 of episode 0 completed. Loss: 9433.1592\n",
      "Step 282 of episode 0 completed. Loss: 7226.8730\n",
      "Step 283 of episode 0 completed. Loss: 6052.1279\n",
      "Step 284 of episode 0 completed. Loss: 3119.3789\n",
      "Step 285 of episode 0 completed. Loss: 1667.8383\n",
      "Step 286 of episode 0 completed. Loss: 333.1438\n",
      "Step 287 of episode 0 completed. Loss: -496.2571\n",
      "Step 288 of episode 0 completed. Loss: -478.3054\n",
      "Step 289 of episode 0 completed. Loss: 345.0721\n",
      "Step 290 of episode 0 completed. Loss: 882.5031\n",
      "Step 291 of episode 0 completed. Loss: 1457.5825\n",
      "Step 292 of episode 0 completed. Loss: 1533.9553\n",
      "Step 293 of episode 0 completed. Loss: 1204.3894\n",
      "Step 294 of episode 0 completed. Loss: 1499.5490\n",
      "Step 295 of episode 0 completed. Loss: 1360.7432\n",
      "Step 296 of episode 0 completed. Loss: 1082.2272\n",
      "Step 297 of episode 0 completed. Loss: 445.0712\n",
      "Step 298 of episode 0 completed. Loss: -52.4460\n",
      "Step 299 of episode 0 completed. Loss: -77.0243\n",
      "Step 300 of episode 0 completed. Loss: -218.0204\n",
      "Step 301 of episode 0 completed. Loss: 1327.9062\n",
      "Step 302 of episode 0 completed. Loss: 20869.6680\n",
      "Step 303 of episode 0 completed. Loss: 2142.4141\n",
      "Step 304 of episode 0 completed. Loss: 2199.2100\n",
      "Step 305 of episode 0 completed. Loss: 1610.2072\n",
      "Step 306 of episode 0 completed. Loss: 8222.8066\n",
      "Step 307 of episode 0 completed. Loss: 2844.1680\n",
      "Step 308 of episode 0 completed. Loss: 139.9646\n",
      "Step 309 of episode 0 completed. Loss: 5290.8408\n",
      "Step 310 of episode 0 completed. Loss: 5233.2275\n",
      "Step 311 of episode 0 completed. Loss: 5267.8018\n",
      "Step 312 of episode 0 completed. Loss: 19087.3281\n",
      "Step 313 of episode 0 completed. Loss: 14637.9170\n",
      "Step 314 of episode 0 completed. Loss: 11441.5996\n",
      "Step 315 of episode 0 completed. Loss: 24101.7031\n",
      "Step 316 of episode 0 completed. Loss: 23979.8711\n",
      "Step 317 of episode 0 completed. Loss: 8935.3613\n",
      "Step 318 of episode 0 completed. Loss: 1762.9727\n",
      "Step 319 of episode 0 completed. Loss: -230.4488\n",
      "Step 320 of episode 0 completed. Loss: -246.1274\n",
      "Step 321 of episode 0 completed. Loss: -345.3596\n",
      "Step 322 of episode 0 completed. Loss: -280.8860\n",
      "Step 323 of episode 0 completed. Loss: -179.7272\n",
      "Step 324 of episode 0 completed. Loss: 2575.5466\n",
      "Step 325 of episode 0 completed. Loss: 2681.9197\n",
      "Step 326 of episode 0 completed. Loss: 2509.7617\n",
      "Step 327 of episode 0 completed. Loss: 7485.1709\n",
      "Step 328 of episode 0 completed. Loss: 2406.0522\n",
      "Step 329 of episode 0 completed. Loss: 779.2040\n",
      "Step 330 of episode 0 completed. Loss: 481.8518\n",
      "Step 331 of episode 0 completed. Loss: 395.8487\n",
      "Step 332 of episode 0 completed. Loss: 1209.7563\n",
      "Step 333 of episode 0 completed. Loss: 8820.4180\n",
      "Step 334 of episode 0 completed. Loss: 7582.3267\n",
      "Step 335 of episode 0 completed. Loss: 316.3636\n",
      "Step 336 of episode 0 completed. Loss: 2732.0396\n",
      "Step 337 of episode 0 completed. Loss: 348.2436\n",
      "Step 338 of episode 0 completed. Loss: -99.1215\n",
      "Step 339 of episode 0 completed. Loss: 323.4738\n",
      "Step 340 of episode 0 completed. Loss: -14.8777\n",
      "Step 341 of episode 0 completed. Loss: -284.6039\n",
      "Step 342 of episode 0 completed. Loss: 285.5401\n",
      "Step 343 of episode 0 completed. Loss: 1305.3807\n",
      "Step 344 of episode 0 completed. Loss: 2492.0605\n",
      "Step 345 of episode 0 completed. Loss: -49.0052\n",
      "Step 346 of episode 0 completed. Loss: -77.9560\n",
      "Step 347 of episode 0 completed. Loss: -49.9758\n",
      "Step 348 of episode 0 completed. Loss: 541.9593\n",
      "Step 349 of episode 0 completed. Loss: 195.2162\n",
      "Step 350 of episode 0 completed. Loss: 184.2661\n",
      "Step 351 of episode 0 completed. Loss: 27.7311\n",
      "Step 352 of episode 0 completed. Loss: -300.6556\n",
      "Step 353 of episode 0 completed. Loss: -267.3635\n",
      "Step 354 of episode 0 completed. Loss: -314.1155\n",
      "Step 355 of episode 0 completed. Loss: 457.2980\n",
      "Step 356 of episode 0 completed. Loss: -189.7568\n",
      "Step 357 of episode 0 completed. Loss: -237.4451\n",
      "Step 358 of episode 0 completed. Loss: -183.5263\n",
      "Step 359 of episode 0 completed. Loss: -132.7368\n",
      "Step 360 of episode 0 completed. Loss: -268.5130\n",
      "Step 361 of episode 0 completed. Loss: 10367.0840\n",
      "Step 362 of episode 0 completed. Loss: 36471.0547\n",
      "Step 363 of episode 0 completed. Loss: 80909.8594\n",
      "Step 364 of episode 0 completed. Loss: 129241.1484\n",
      "Step 365 of episode 0 completed. Loss: 186026.3125\n",
      "Step 366 of episode 0 completed. Loss: 205699.0000\n",
      "Step 367 of episode 0 completed. Loss: 210042.9062\n",
      "Step 368 of episode 0 completed. Loss: 220669.6875\n",
      "Step 369 of episode 0 completed. Loss: 227857.3438\n",
      "Step 370 of episode 0 completed. Loss: 231286.2500\n",
      "Step 371 of episode 0 completed. Loss: 221897.2344\n",
      "Step 372 of episode 0 completed. Loss: 202537.3750\n",
      "Step 373 of episode 0 completed. Loss: 180100.4375\n",
      "Step 374 of episode 0 completed. Loss: 159716.3438\n",
      "Step 375 of episode 0 completed. Loss: 138451.2500\n",
      "Step 376 of episode 0 completed. Loss: 118117.6719\n",
      "Step 377 of episode 0 completed. Loss: 104090.2188\n",
      "Step 378 of episode 0 completed. Loss: 92117.0000\n",
      "Step 379 of episode 0 completed. Loss: 82380.8594\n",
      "Step 380 of episode 0 completed. Loss: 75303.0625\n",
      "Step 381 of episode 0 completed. Loss: 86754.2812\n",
      "Step 382 of episode 0 completed. Loss: 90417.7188\n",
      "Step 383 of episode 0 completed. Loss: 78451.7500\n",
      "Step 384 of episode 0 completed. Loss: 67745.2500\n",
      "Step 385 of episode 0 completed. Loss: 58178.6172\n",
      "Step 386 of episode 0 completed. Loss: 50718.4062\n",
      "Step 387 of episode 0 completed. Loss: 44993.6836\n",
      "Step 388 of episode 0 completed. Loss: 40657.0469\n",
      "Step 389 of episode 0 completed. Loss: 35578.2969\n",
      "Step 390 of episode 0 completed. Loss: 30927.3984\n",
      "Step 391 of episode 0 completed. Loss: 27217.7578\n",
      "Step 392 of episode 0 completed. Loss: 24012.2520\n",
      "Step 393 of episode 0 completed. Loss: 21235.1055\n",
      "Step 394 of episode 0 completed. Loss: 18824.1758\n",
      "Step 395 of episode 0 completed. Loss: 16724.5488\n",
      "Step 396 of episode 0 completed. Loss: 14891.2305\n",
      "Step 397 of episode 0 completed. Loss: 13293.1699\n",
      "Step 398 of episode 0 completed. Loss: 11998.3516\n",
      "Step 399 of episode 0 completed. Loss: 10790.4121\n",
      "Step 400 of episode 0 completed. Loss: 9607.1445\n",
      "Step 401 of episode 0 completed. Loss: 262.9289\n",
      "Step 402 of episode 0 completed. Loss: -1003.4680\n",
      "Step 403 of episode 0 completed. Loss: 2732.7256\n",
      "Step 404 of episode 0 completed. Loss: 4811.6436\n",
      "Step 405 of episode 0 completed. Loss: 5699.4644\n",
      "Step 406 of episode 0 completed. Loss: 6474.9897\n",
      "Step 407 of episode 0 completed. Loss: 37557.7422\n",
      "Step 408 of episode 0 completed. Loss: 40046.3125\n",
      "Step 409 of episode 0 completed. Loss: 41127.9844\n",
      "Step 410 of episode 0 completed. Loss: 91092.8047\n",
      "Step 411 of episode 0 completed. Loss: 79064.0234\n",
      "Step 412 of episode 0 completed. Loss: 74206.9219\n",
      "Step 413 of episode 0 completed. Loss: 117958.3594\n",
      "Step 414 of episode 0 completed. Loss: 59740.6016\n",
      "Step 415 of episode 0 completed. Loss: 27038.3711\n",
      "Step 416 of episode 0 completed. Loss: 10076.8740\n",
      "Step 417 of episode 0 completed. Loss: 7965.6338\n",
      "Step 418 of episode 0 completed. Loss: 11967.3965\n",
      "Step 419 of episode 0 completed. Loss: -532.1946\n",
      "Step 420 of episode 0 completed. Loss: 3011.7202\n",
      "Step 421 of episode 0 completed. Loss: 5513.5859\n",
      "Step 422 of episode 0 completed. Loss: 6632.7871\n",
      "Step 423 of episode 0 completed. Loss: 34.2003\n",
      "Step 424 of episode 0 completed. Loss: 286.7104\n",
      "Step 425 of episode 0 completed. Loss: 13065.4824\n",
      "Step 426 of episode 0 completed. Loss: 203.4072\n",
      "Step 427 of episode 0 completed. Loss: 135.3241\n",
      "Step 428 of episode 0 completed. Loss: 3148.9688\n",
      "Step 429 of episode 0 completed. Loss: 919.9342\n",
      "Step 430 of episode 0 completed. Loss: 469.9587\n",
      "Step 431 of episode 0 completed. Loss: 6836.1377\n",
      "Step 432 of episode 0 completed. Loss: 178.2718\n",
      "Step 433 of episode 0 completed. Loss: 193.5347\n",
      "Step 434 of episode 0 completed. Loss: 4750.5215\n",
      "Step 435 of episode 0 completed. Loss: 354.8076\n",
      "Step 436 of episode 0 completed. Loss: 3749.8364\n",
      "Step 437 of episode 0 completed. Loss: 2336.4800\n",
      "Step 438 of episode 0 completed. Loss: 1330.6117\n",
      "Step 439 of episode 0 completed. Loss: 176.1774\n",
      "Step 440 of episode 0 completed. Loss: -236.3890\n",
      "Step 441 of episode 0 completed. Loss: -194.2874\n",
      "Step 442 of episode 0 completed. Loss: 1620.1311\n",
      "Step 443 of episode 0 completed. Loss: 548.0210\n",
      "Step 444 of episode 0 completed. Loss: -310.1393\n",
      "Step 445 of episode 0 completed. Loss: 1451.5763\n",
      "Step 446 of episode 0 completed. Loss: -25.0860\n",
      "Step 447 of episode 0 completed. Loss: 4032.7754\n",
      "Step 448 of episode 0 completed. Loss: 7971.7051\n",
      "Step 449 of episode 0 completed. Loss: 5098.8037\n",
      "Step 450 of episode 0 completed. Loss: 13203.2656\n",
      "Step 451 of episode 0 completed. Loss: 22611.8672\n",
      "Step 452 of episode 0 completed. Loss: 29941.4609\n",
      "Step 453 of episode 0 completed. Loss: 39084.2031\n",
      "Step 454 of episode 0 completed. Loss: 48726.8906\n",
      "Step 455 of episode 0 completed. Loss: 55205.8477\n",
      "Step 456 of episode 0 completed. Loss: 56473.9688\n",
      "Step 457 of episode 0 completed. Loss: 54071.3984\n",
      "Step 458 of episode 0 completed. Loss: 54450.9922\n",
      "Step 459 of episode 0 completed. Loss: 48810.2031\n",
      "Step 460 of episode 0 completed. Loss: 45735.0625\n",
      "Step 461 of episode 0 completed. Loss: 41804.4805\n",
      "Step 462 of episode 0 completed. Loss: 36613.5547\n",
      "Step 463 of episode 0 completed. Loss: 32459.4668\n",
      "Step 464 of episode 0 completed. Loss: 29206.0586\n",
      "Step 465 of episode 0 completed. Loss: 24534.8359\n",
      "Step 466 of episode 0 completed. Loss: 20672.9805\n",
      "Step 467 of episode 0 completed. Loss: 17472.3340\n",
      "Step 468 of episode 0 completed. Loss: 515.1107\n",
      "Step 469 of episode 0 completed. Loss: 8531.2158\n",
      "Step 470 of episode 0 completed. Loss: 20082.6758\n",
      "Step 471 of episode 0 completed. Loss: 33880.0430\n",
      "Step 472 of episode 0 completed. Loss: 55020.1641\n",
      "Step 473 of episode 0 completed. Loss: 80528.3906\n",
      "Step 474 of episode 0 completed. Loss: 110109.4531\n",
      "Step 475 of episode 0 completed. Loss: 138606.4062\n",
      "Step 476 of episode 0 completed. Loss: 166416.3125\n",
      "Step 477 of episode 0 completed. Loss: 203319.6875\n",
      "Step 478 of episode 0 completed. Loss: 242881.9375\n",
      "Step 479 of episode 0 completed. Loss: 284799.8125\n",
      "Step 480 of episode 0 completed. Loss: 328728.5000\n",
      "Step 481 of episode 0 completed. Loss: 362708.1562\n",
      "Step 482 of episode 0 completed. Loss: 408789.0000\n",
      "Step 483 of episode 0 completed. Loss: 455607.2500\n",
      "Step 484 of episode 0 completed. Loss: 502580.0938\n",
      "Step 485 of episode 0 completed. Loss: 533786.1875\n",
      "Step 486 of episode 0 completed. Loss: 562897.1250\n",
      "Step 487 of episode 0 completed. Loss: 602657.6250\n",
      "Step 488 of episode 0 completed. Loss: 646604.8750\n",
      "Step 489 of episode 0 completed. Loss: 687058.5000\n",
      "Step 490 of episode 0 completed. Loss: 722796.7500\n",
      "Step 491 of episode 0 completed. Loss: 741629.3125\n",
      "Step 492 of episode 0 completed. Loss: 757918.3750\n",
      "Step 493 of episode 0 completed. Loss: 769057.3125\n",
      "Step 494 of episode 0 completed. Loss: 769697.5000\n",
      "Step 495 of episode 0 completed. Loss: 757513.0000\n",
      "Step 496 of episode 0 completed. Loss: 658698.2500\n",
      "Step 497 of episode 0 completed. Loss: 564842.4375\n",
      "Step 498 of episode 0 completed. Loss: 525733.8750\n",
      "Step 499 of episode 0 completed. Loss: 463798.0312\n",
      "Step 500 of episode 0 completed. Loss: 407189.1875\n",
      "Step 501 of episode 0 completed. Loss: 243075.5000\n",
      "Step 502 of episode 0 completed. Loss: 133454.4688\n",
      "Step 503 of episode 0 completed. Loss: 63781.7031\n",
      "Step 504 of episode 0 completed. Loss: 71885.8281\n",
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'player' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 123\u001b[0m\n\u001b[1;32m    119\u001b[0m reward_history\u001b[38;5;241m.\u001b[39mappend(rewards[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayer_0\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# calc l2 norm\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m network_dif \u001b[38;5;241m=\u001b[39m compute_network_difference(players[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayer_0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnet, \u001b[43mplayer\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayers_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnet)\n\u001b[1;32m    124\u001b[0m network_difs\u001b[38;5;241m.\u001b[39mappend(network_dif)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# update adversary to current state dict every 5 episodes\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'player' is not defined"
     ]
    }
   ],
   "source": [
    "# set some hyperparams\n",
    "episode_num = 0\n",
    "reward_history = []\n",
    "network_difs = []\n",
    "wins = 0\n",
    "gamma = 0.99\n",
    "lambda_ = 0.95\n",
    "value_coeff=0.5\n",
    "entropy_coeff=0.01\n",
    "win_rates = []\n",
    "\n",
    "while True:\n",
    "    obs, info = env.reset()\n",
    "    game_done = False\n",
    "    wins = 0\n",
    "    step = 0\n",
    "    last_obs = {}\n",
    "    last_actions = {}\n",
    "    print(f\"episode num: {episode_num}\")\n",
    "\n",
    "    # initialize rewards array and trajectories\n",
    "    rewards = {\n",
    "        \"player_0\": [],\n",
    "        \"player_1\": []\n",
    "    }\n",
    "\n",
    "    # save last env reward \n",
    "    last_env_reward = {\n",
    "        \"player_0\": np.zeros(1, dtype=np.int32),\n",
    "        \"player_1\": np.zeros(1, dtype=np.int32)\n",
    "    }\n",
    "    \n",
    "    while not game_done:\n",
    "        actions = {}\n",
    "        # store current observations for learning\n",
    "        last_obs = {\n",
    "            \"player_0\": obs[\"player_0\"].copy(),\n",
    "            \"player_1\": obs[\"player_1\"].copy()\n",
    "        }\n",
    "\n",
    "        # get network output, including actions\n",
    "        network_outs = {}\n",
    "        for id_, agent in players.items():\n",
    "            \n",
    "            network_outs[id_] = agent.act_train(step=step, obs=obs[id_])\n",
    "\n",
    "            actions[id_] = agent.sample_actions(network_outs[id_][1], network_outs[id_][2])\n",
    "\n",
    "            # save actions\n",
    "            last_actions[id_] = actions.copy()\n",
    "\n",
    "         \n",
    "        # step in environment for both agents\n",
    "        obs, reward, terminated, truncated, info = env.step(actions)\n",
    "        match_result = None\n",
    "        if (last_env_reward != reward):\n",
    "            if reward[\"player_0\"] > last_env_reward[\"player_0\"]:\n",
    "                match_result = \"win\"\n",
    "            elif reward[\"player_1\"] > last_env_reward[\"player_1\"]:\n",
    "                match_result = \"loss\"\n",
    "            else:\n",
    "                match_result = \"draw\"\n",
    "\n",
    "        last_env_reward = reward.copy()\n",
    "\n",
    "        # calc rewards for both agents\n",
    "        for id_, agent in players.items():\n",
    "            map_memory, enemy_memory, ally_memory, relic_points, _, _ = agent.process_obs(obs[id_])\n",
    "            rewards[id_].append(calculate_rewards(network_outs[id_][0].squeeze(0).detach().cpu().numpy(), map_memory, enemy_memory, ally_memory, relic_points, match_result))\n",
    "            \n",
    "\n",
    "        # calc whether game is finished\n",
    "        dones = {k: terminated[k] | truncated[k] for k in terminated}\n",
    "\n",
    "        # Compute returns and advantages for player 0\n",
    "        returns, advantages = compute_advantages(\n",
    "            rewards=[rewards[\"player_0\"][-1]],\n",
    "            values=[network_outs[\"player_0\"][3].squeeze(0).squeeze(-1).detach().cpu().numpy()],\n",
    "            gamma=gamma,\n",
    "            lambda_=lambda_\n",
    "        )\n",
    "\n",
    "        # compute losses\n",
    "        weight_loss = compute_weight_loss(\n",
    "            log_probs=torch.cat((network_outs[\"player_0\"][1].log(), network_outs[\"player_0\"][2].log()), dim=-1).to(device),\n",
    "            advantages=torch.tensor(advantages, dtype=torch.float32).to(device),\n",
    "            values=network_outs[\"player_0\"][3].squeeze(-1),\n",
    "            returns=torch.tensor(returns, dtype=torch.float32).to(device),\n",
    "            entropy_coeff=entropy_coeff,\n",
    "            value_coeff=value_coeff\n",
    "        )\n",
    "        action_loss = compute_action_loss(\n",
    "            log_probs=network_outs[\"player_0\"][1].log(),\n",
    "            advantages=torch.tensor(advantages, dtype=torch.float32).to(device),\n",
    "            values=network_outs[\"player_0\"][3].squeeze(-1),\n",
    "            returns=torch.tensor(returns, dtype=torch.float32).to(device),\n",
    "            entropy_coeff=entropy_coeff,\n",
    "            value_coeff=value_coeff\n",
    "        )\n",
    "    \n",
    "        # backpropogation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss = weight_loss + action_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Step {step} of episode {episode_num} completed. Loss: {total_loss.item():.4f}\")\n",
    "\n",
    "        if dones[\"player_0\"] or dones[\"player_1\"]:\n",
    "            game_done = True\n",
    "            # save model weights\n",
    "            torch.save(players[\"player_0\"].net.state_dict(), f\"models/agent_network_episode_{episode_num}\")\n",
    "            wins += int(reward[\"player_0\"] > reward[\"player_1\"])\n",
    "            print(wins)\n",
    "            win_rates.append(wins / (episode_num + 1))\n",
    "        step += 1\n",
    "\n",
    "    # store rewards\n",
    "    reward_history.append(rewards[\"player_0\"])\n",
    "   \n",
    "\n",
    "    # calc l2 norm\n",
    "    network_dif = compute_network_difference(players[\"player_0\"].net, players[\"players_1\"].net)\n",
    "    network_difs.append(network_dif)\n",
    "\n",
    "    # update adversary to current state dict every 5 episodes\n",
    "    if episode_num % 5 == 0:\n",
    "        players[\"player_1\"].net.load_state_dict(players[\"player_0\"].net.state_dict())\n",
    "\n",
    "    # if network has converged according to our criterion break out of training loop\n",
    "    if has_converged(win_rates, network_difs):\n",
    "        break\n",
    "        \n",
    "    episode_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679f8e2-5a1a-479c-9d9c-f4c1296f2b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822a2aa4-65aa-4b98-b4ac-f21f09918777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db2411-e81f-47f9-91a9-b0615f95e531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465149cd-f249-4d74-8006-c9c1aea35e8e",
   "metadata": {},
   "source": [
    "### this notebook is for training our Agent in the lux environment and see how well we do :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fef873-ccc1-4ce2-bb74-d5a74cee1479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from luxai_s3.wrappers import LuxAIS3GymEnv\n",
    "from agent import Agent\n",
    "from network import AgentNetwork, compute_network_difference, has_converged\n",
    "from rewards import calculate_rewards\n",
    "from ac2methods import compute_advantages, compute_weight_loss, compute_action_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929f67f5-870e-4fa9-a0e1-47086019e6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-01-25 20:20:25,418:jax._src.xla_bridge:987: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "# reset our gym environment\n",
    "env = LuxAIS3GymEnv(numpy_output=True)\n",
    "obs, info = env.reset()\n",
    "\n",
    "env_cfg = info[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c346dbe-184e-44ea-86c9-36f360152951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set torch device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98cf25d8-8d9e-462e-bacc-8bf36350b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set players\n",
    "players = {\n",
    "    \"player_0\": Agent(\"player_0\", env_cfg, AgentNetwork((env_cfg[\"map_width\"], env_cfg[\"map_height\"]), env_cfg[\"max_units\"], 6).to(device), device),\n",
    "    \"player_1\": Agent(\"player_1\", env_cfg, AgentNetwork((env_cfg[\"map_width\"], env_cfg[\"map_height\"]), env_cfg[\"max_units\"], 6).to(device), device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ecc61c-0b05-4fdc-9ba7-895cc461d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer for network\n",
    "optimizer = torch.optim.Adam(players[\"player_0\"].net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "906c9da1-b84f-4932-b22c-20124a7ca50e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode num: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m network_outs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m id_, agent \u001b[38;5;129;01min\u001b[39;00m players\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 44\u001b[0m     network_outs[id_] \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mid_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     actions[id_] \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39msample_actions(network_outs[id_][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu(), network_outs[id_][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# save actions\u001b[39;00m\n",
      "File \u001b[0;32m~/lux_s3_submission/agent.py:52\u001b[0m, in \u001b[0;36mAgent.act_train\u001b[0;34m(self, step, obs, remainingOverageTime)\u001b[0m\n\u001b[1;32m     49\u001b[0m map_memory[:, :, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m StandardScaler()\u001b[38;5;241m.\u001b[39mfit_transform(map_memory[:, :, \u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# standard scaler for energy and recency values\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m enemy_memory[:, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mStandardScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43menemy_memory\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m enemy_memory[:, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m StandardScaler()\u001b[38;5;241m.\u001b[39mfit_transform(enemy_memory[:, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# standard scaler for energy and recency values\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    903\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    904\u001b[0m             (\n\u001b[1;32m    905\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    914\u001b[0m         )\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:894\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:930\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \n\u001b[1;32m    900\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    929\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 930\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/sklearn/utils/validation.py:1093\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1087\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1088\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1089\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1092\u001b[0m             )\n\u001b[0;32m-> 1093\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1099\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# set some hyperparams\n",
    "episode_num = 0\n",
    "reward_history = []\n",
    "network_difs = []\n",
    "wins = 0\n",
    "gamma = 0.99\n",
    "lambda_ = 0.95\n",
    "value_coeff=0.5\n",
    "entropy_coeff=0.01\n",
    "win_rates = []\n",
    "\n",
    "while True:\n",
    "    obs, info = env.reset()\n",
    "    game_done = False\n",
    "    step = 0\n",
    "    last_obs = {}\n",
    "    last_actions = {}\n",
    "    print(f\"episode num: {episode_num}\")\n",
    "\n",
    "    # initialize rewards array and trajectories\n",
    "    rewards = {\n",
    "        \"player_0\": [],\n",
    "        \"player_1\": []\n",
    "    }\n",
    "\n",
    "    # save last env reward \n",
    "    last_env_reward = {\n",
    "        \"player_0\": np.zeros(1, dtype=np.int32),\n",
    "        \"player_1\": np.zeros(1, dtype=np.int32)\n",
    "    }\n",
    "    \n",
    "    while not game_done:\n",
    "        actions = {}\n",
    "        # store current observations for learning\n",
    "        last_obs = {\n",
    "            \"player_0\": obs[\"player_0\"].copy(),\n",
    "            \"player_1\": obs[\"player_1\"].copy()\n",
    "        }\n",
    "\n",
    "        # get network output, including actions\n",
    "        network_outs = {}\n",
    "        for id_, agent in players.items():\n",
    "            \n",
    "            network_outs[id_] = agent.act_train(step=step, obs=obs[id_])\n",
    "\n",
    "            actions[id_] = agent.sample_actions(network_outs[id_][1].detach().cpu(), network_outs[id_][2].detach().cpu())\n",
    "\n",
    "            # save actions\n",
    "            last_actions[id_] = actions.copy()\n",
    "\n",
    "         \n",
    "        # step in environment for both agents\n",
    "        obs, reward, terminated, truncated, info = env.step(actions)\n",
    "        match_result = None\n",
    "        if (last_env_reward != reward):\n",
    "            if reward[\"player_0\"] > last_env_reward[\"player_0\"]:\n",
    "                match_result = \"win\"\n",
    "            elif reward[\"player_1\"] > last_env_reward[\"player_1\"]:\n",
    "                match_result = \"loss\"\n",
    "            else:\n",
    "                match_result = \"draw\"\n",
    "\n",
    "        last_env_reward = reward.copy()\n",
    "\n",
    "        # calc rewards for both agents\n",
    "        for id_, agent in players.items():\n",
    "            map_memory, enemy_memory, ally_memory, relic_points, _, _ = agent.process_obs(obs[id_])\n",
    "            rewards[id_].append(calculate_rewards(network_outs[id_][0].squeeze(0).detach().cpu().numpy(), map_memory, enemy_memory, ally_memory, relic_points, match_result))\n",
    "            \n",
    "\n",
    "        # calc whether game is finished\n",
    "        dones = {k: terminated[k] | truncated[k] for k in terminated}\n",
    "\n",
    "        # Compute returns and advantages for player 0\n",
    "        returns, advantages = compute_advantages(\n",
    "            rewards=[rewards[\"player_0\"][-1]],\n",
    "            values=[network_outs[\"player_0\"][3].squeeze(0).squeeze(-1).detach().cpu().numpy()],\n",
    "            gamma=gamma,\n",
    "            lambda_=lambda_\n",
    "        )\n",
    "\n",
    "        # compute losses\n",
    "        weight_loss = compute_weight_loss(\n",
    "            log_probs=torch.cat((network_outs[\"player_0\"][1].log(), network_outs[\"player_0\"][2].log()), dim=-1).to(device),\n",
    "            advantages=torch.tensor(advantages, dtype=torch.float32).to(device),\n",
    "            values=network_outs[\"player_0\"][3].squeeze(-1),\n",
    "            returns=torch.tensor(returns, dtype=torch.float32).to(device),\n",
    "            entropy_coeff=entropy_coeff,\n",
    "            value_coeff=value_coeff\n",
    "        )\n",
    "        action_loss = compute_action_loss(\n",
    "            log_probs=network_outs[\"player_0\"][1].log(),\n",
    "            advantages=torch.tensor(advantages, dtype=torch.float32).to(device),\n",
    "            values=network_outs[\"player_0\"][3].squeeze(-1),\n",
    "            returns=torch.tensor(returns, dtype=torch.float32).to(device),\n",
    "            entropy_coeff=entropy_coeff,\n",
    "            value_coeff=value_coeff\n",
    "        )\n",
    "    \n",
    "        # backpropogation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss = weight_loss + action_loss\n",
    "        total_loss.backward()\n",
    "        # clip gradients to prevent overflow\n",
    "        torch.nn.utils.clip_grad_norm_(players[\"player_0\"].net.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Step {step} of episode {episode_num} completed. Loss: {total_loss.item():.4f}\")\n",
    "\n",
    "        if dones[\"player_0\"] or dones[\"player_1\"]:\n",
    "            game_done = True\n",
    "            # save model weights\n",
    "            torch.save(players[\"player_0\"].net.state_dict(), f\"models/agent_network_episode_{episode_num}\")\n",
    "            wins += int(reward[\"player_0\"] > reward[\"player_1\"])\n",
    "            print(wins)\n",
    "            win_rates.append(wins / (episode_num + 1))\n",
    "        step += 1\n",
    "\n",
    "    # store rewards\n",
    "    reward_history.append(rewards[\"player_0\"])\n",
    "   \n",
    "\n",
    "    # calc l2 norm\n",
    "    network_dif = compute_network_difference(players[\"player_0\"].net, players[\"player_1\"].net)\n",
    "    network_difs.append(network_dif)\n",
    "\n",
    "    # update adversary to current state dict every 5 episodes\n",
    "    if episode_num % 5 == 0:\n",
    "        players[\"player_1\"].net.load_state_dict(players[\"player_0\"].net.state_dict())\n",
    "\n",
    "    # if network has converged according to our criterion break out of training loop\n",
    "    if has_converged(win_rates, network_difs):\n",
    "        print(f\"agent converged after {episode_num + 1} episodes!\")\n",
    "        break\n",
    "        \n",
    "    episode_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679f8e2-5a1a-479c-9d9c-f4c1296f2b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822a2aa4-65aa-4b98-b4ac-f21f09918777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db2411-e81f-47f9-91a9-b0615f95e531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b712eb-f068-4be5-934d-60f32053a790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
